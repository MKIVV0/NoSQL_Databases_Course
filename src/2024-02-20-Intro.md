# Course Introduction - February 20th, 2024

## Why opt for Non-Relational Databases?
In an era increasingly driven by technology, the sheer<sup><a id="footnote-1-ref" href=#footnote-1>[1]</a></sup> <b>volume of data</b> processed by devices, such as computers, is experiencing <b>exponential growth</b>. This prompts a critical question: <strong>why do we need a class of databases that diverges from traditional relational models?</strong>
<br><br>
Given the vast volume of information processed and exchanged by computers in today's world, originating from <b>diverse sources</b> and exhibiting <b>various structures</b>, there's a compelling need for systems that are fast, reliable, and efficient in handling such diverse datasets.
<br><br>
In such a case, we can use the term <strong>Big Data</strong> to refer to information that contains greater variety arriving in increasing volumes and with ever-higher velocity. In particular, this term refers to datasets whose size is beyond the ability of typical database software tools to capture, store, manage, and analyze. We have, therefore, three dimensions that characterize this class of data:
<ul>
    <li><strong>Variety</strong>, which refers to the diverse types of data that can be encountered. This includes structured data (e.g., databases), unstructured data (e.g., text, images, videos), and semi-structured data (e.g., XML and JSON files).</li>
    <li><strong>Volume</strong>, which represent the sheer size or scale of the data being generated or collected. It refers to the vast amounts of data that exced the capacity of traditional database systems.</li>
    <li><strong>Velocity</strong>, the speed at which data is generated, processed, and made available for analysis. It emphasizes the real-time or near-real-time nature of data streams.</li>
</ul>
The following image shows a diagram comparing <b>big data</b> and <b>normal processing capabilities</b>. It depicts the vast difference in the amount of data that big data can handle compared to normal processing capacity:
<br><br>
<div style="text-align:center">
  <img src="./imgs/Big%20Data%20vs%20Normal%20Data.png" alt="Big Data vs Normal Data" style="width:80%; max-width:600px;">
</div>

## How can we quantify big data?
The <b>overwhelming volume</b> of data is a key aspect in big data. Traditionally, datasets on the order of <b>terabytes (TB)</b>, <b>petabytes (PB)</b>, or even <b>zettabytes (ZB)</b>, are considered as falling into the realm of big data.
For comparison purposes, here is the <b>byte scale</b>:
- \\(1\ Zettabyte = 2^{70}\ bytes\\)
- \\(1\ Exabyte = 2^{60}\ bytes\\)
- \\(1\ Petabyte = 2^{50}\ bytes\\)
- \\(1\ Terabyte = 2^{40}\ bytes\\)
- \\(1\ Gigabyte = 2^{30}\ bytes\\) 
- \\(1\ Megabyte = 2^{20}\ bytes\\) 
- \\(1\ Kilobyte = 2^{10}\ bytes\\) 
- \\(1\ Byte = 2^{3}\ bits\\) 

These values illustrate the increasing magnitudes of data storage.
The following image shows how the global generation of data increases annually:
<div style="text-align:center">
    <img src="./imgs/Global Data Generated Annually.png" alt="Global Data Generated Annually" style="width:80%; max-width:600px">
    <p>Reference: <a href="https://explodingtopics.com/blog/data-generated-per-day"> explodingtopics.com (2024)</a></p>
</div>

## What kind of data are we considering?
As mentioned before, data can be classified into three categories:
- <b>Structured Data</b> refers to well-organized, tabular data with a clear schema. This includes data stored in relational databases and spreadsheets. Big data applications may involve large volumes of structured data, especially when dealing with historical records, transactional data, or standardized information. <br>
- <b>Semi-structured Data</b> is a class of data that has some level of structure, but does not conform to the rigid structure of traditional relational databases. It may have tags, hierarchies, or key-value pairs. JSON and XML are included in this class. Big data applications may leverage semi-structured data formats for flexibility and scalability, such as handling data with varying attributes or evolving schemas. <br>
- <b>Unstructured Data</b> is a category of data that lacks a predefined data model or is not organized in a tabular structure. It includes text, images, audio, and video. Big data applications often deal with massive amounts of unstructured data, such as sentiment analysis on social media, image recognition, or natural language processing.

In fact, the following image shows the increasing treatment of unstructured data over structured data, as time goes on:
<div style="text-align:center">
    <img src="./imgs/Unstructured Data vs Structured Data.jpg" alt="Unstructured Data vs Structured Data" style="width:80%; max-width:600px">
    <p>Reference: <a href="https://e.huawei.com/en/articles/storage/2021/all-flash-data-center-green-energy">Huawei GIV (2021)</a></p>
</div>

As for Big Data sources, they comprise <b>social networks</b>, <b>logs of various web/email servers or routers</b>, <b>sensor networks</b>, <b>IoT devices</b>.

## Data Processing
In the expansive landscape of big data, efficient data processing is achieved through the orchestration of three key paradigms:
- <b>OLTP (Online Transaction Processing)</b>;
- <b>OLAP (Online Analytical Processing)</b>:
- <b>RTAP (Real-Time Analytics Processing)</b>.

## Notes
<p id="footnote-1"><a href=#footnote-1-ref>[1]</a> with "sheer", we're emphasizing the magnitude, the size of the data, without introducing qualifiers or restrictions.
